import os
import tempfile
import streamlit as st
from dotenv import load_dotenv
from autogen import AssistantAgent, UserProxyAgent
from tools import  retrieve_doc_context  
from rag_index import build_index_from_file

load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
openai_model = os.getenv("OPENAI_MODEL")

llm_config = {
    "config_list": [
        {
            "model": openai_model,
            "api_key": openai_api_key
        }
    ]
}

def is_termination_msg(msg):
    return msg.get("content") and "TERMINATE" in msg["content"]

# Core agent function
def run_agent(query):
    doc_assistant = AssistantAgent(
        name="DocAssistant",
        system_message=(
            "You are a helpful document assistant that answers user queries ONLY by calling the 'retrieve_doc_context' tool. "
            "After answering, always respond with 'TERMINATE' to end the chat."
        ),
        llm_config=llm_config,
    )

    user = UserProxyAgent(
        name="User",
        llm_config=False,
        human_input_mode="NEVER",
        is_termination_msg=is_termination_msg,
        code_execution_config={"use_docker": False}
    )

    doc_assistant.register_for_llm(
        name="retrieve_doc_context",
        description="Retrieve relevant context from the indexed documents (PDF, DOCX, PPTX) based on the query."
    )(retrieve_doc_context)

    user.register_for_execution(
        name="retrieve_doc_context"
    )(retrieve_doc_context)

    chat_result = user.initiate_chat(
        doc_assistant,
        message=query,
        summary_method="reflection_with_llm"
    )

    history = getattr(chat_result, "chat_history", None)
    if history is None:
        return "No chat history found.", []

    # Extract the final assistant message
    for msg in reversed(history):
        if msg.get("role") == "user" and msg.get("name") == "DocAssistant":
            final_content = msg.get("content", "").replace("TERMINATE", "").strip()
            return final_content, history

    return "No valid answer was generated by the assistant.", history


# Streamlit UI
st.set_page_config(page_title="ðŸ“„ Document RAG Assistant", layout="wide")
st.markdown("""
    <div style="
        background: linear-gradient(135deg, #e0f7fa, #ffdde1);
        padding: 25px 35px;
        border-radius: 15px;
        max-width: 850px;
        margin: 0 auto 30px auto;
        text-align: center;
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);
    ">
        <h1 style="
            color: #1a237e;
            font-size: 2.8em;
            margin-bottom: 12px;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        ">
            ðŸ“‘ Multi-Document RAG Assistant
        </h1>
        <p style="
            color: #37474f;
            font-size: 1.15em;
            font-weight: 500;
            line-height: 1.6;
        ">
            Ask any question based on your uploaded document (PDF, Word, PowerPoint)!<br/>
            Powered by Retrieval-Augmented Generation (RAG) & AutoGen ðŸ¤–âœ¨
        </p>
    </div>
""", unsafe_allow_html=True)

st.markdown("Upload your **PDF, DOCX, or PPTX** document and ask any question. Our AI assistant will retrieve and answer from the document content. ðŸ“š")

# File upload (accept PDF, DOCX, PPTX)
uploaded_file = st.file_uploader("ðŸ“Ž Upload your document", type=["pdf", "docx", "pptx"])

if uploaded_file is not None:
    ext = os.path.splitext(uploaded_file.name)[1].lower()
    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_doc_path = tmp_file.name

    st.success(f"âœ… {uploaded_file.name} uploaded successfully!")

    with st.spinner("ðŸ”§ Building FAISS index from uploaded document..."):
        build_index_from_file(tmp_doc_path, persist_dir="rag_faiss_store")
    st.success("ðŸ“š Index built and ready to go!")

    # Query section
    st.markdown("---")
    st.subheader("ðŸ’¬ Ask Your Question")
    query = st.text_input("Type your query here:")

    if query:
        with st.spinner("ðŸ¤– Retrieving answer from RAG Assistant..."):
            answer, chat_history = run_agent(query)

        st.markdown("### ðŸ§  Agent's Answer:")
        st.success(answer)

        # Optional: Expandable chat history
        with st.expander("ðŸ“œ View Full Chat History"):
            for msg in chat_history:
                role = msg.get("role", "").capitalize()
                name = msg.get("name", "")
                content = msg.get("content", "")
                if content:
                    st.markdown(f"**{role} ({name})**: {content}")
else:
    st.info("ðŸ“‚ Please upload a document (PDF/DOCX/PPTX) to begin.")
